% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Appendix}\label{chapter:appendix}

\begin{figure}[!ht]
	\centering
	\begin{tabular}{c}
		\begin{lstlisting}[language=Python]
	  def nn_embedding(features, dimensions):
		talent = Input(shape = (features,))
		project = Input(shape = (features,))
		output_dim = int(dimensions ** 0.25) + 1
		
		talent_embedding = Embedding(dimensions + 1, output_dim,
		input_length=features, mask_zero=True )(talent)
		project_embedding = Embedding(dimensions + 1, output_dim,
		input_length=features, mask_zero=True)(project)
		
		# these are required because of mask zero
		talent_embedding = Lambda(lambda x: x,
		output_shape=lambda s:s)(talent_embedding)
		project_embedding = Lambda(lambda x: x,
		output_shape=lambda s:s)(project_embedding)
		
		merged = Concatenate()([talent_embedding, project_embedding])
		merged = Flatten()(merged)
		merged = Dropout(0.5)(merged)
		main_output = Dense(1, activation='sigmoid')(merged)
		
		model = Model(inputs=[talent, project], outputs=[main_output])
		model.compile(optimizer='adam', loss='binary_crossentropy',
		metrics=["accuracy"])
		
		return model
		\end{lstlisting}
	\end{tabular}
	\caption[Model Code]{The code of the model for both Motius and Freelancer data}\label{fig:model-code}
\end{figure}


\begin{figure}[!ht]
	\centering
	\begin{tabular}{c}
		\begin{lstlisting}[language=Python]
		bias = Input(name = 'bias', shape = (1,))
		talent_bias = Dense(1, activation = 'linear')(bias)
		talent_bias = Activation("tanh")(talent_bias)
		main_output = Add()([output, talent_bias])
		\end{lstlisting}
	\end{tabular}
	\caption[Model Bias Code]{Simplified version of the extra code for enabling feedback}\label{fig:feedback-model-code}
\end{figure}

