% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Implementation}\label{chapter:implementation}

This chapter explains different solutions for the problem at hand. These solutions include applications using datasets from the website Freelancer.com and the company Motius running different methods.

As we mentioned in the Introduction part [See~\autoref{section:motivation}], the implementation of this thesis focuses on recommending the best talents to projects. While serving this aim, we use different datasets and different methods. 


The methods used can be categorized as individual and group recommenders. Individual recommenders have the aim of suggesting only one person to a project. As oppose to that, group recommenders combine multiple subprojects as a super project and recommend various talents to this super project. Another differentiation of these recommenders is the type of learning algorithms. Both group recommenders and the individual recommenders are implemented via supervised and unsupervised learning approaches. The supervised learning approach trains neural networks with the help of ground-truth labels. On the other hand, the unsupervised approach employs training just with the feature vectors ~\parencite{sathya2013comparison}. Detailed information about these methods can be found in the upcoming sections. 

\section{Datasets}\label{section:datasets}

The author of the thesis received two separate but similar datasets. Both of the datasets contain information about projects and talents. The company dataset [See~\autoref{subsection:company-dataset}] is the internal database of the company Motius and includes skill vectors of 795 talents and 375 roles. These roles are parts of bigger projects, which is not the case in Freelancer.com dataset. In Freelancer.com dataset, we have projects as opposed to positions in the Motius dataset. However, we treat the projects in the Freelancer.com data and the roles in the Motius data the same. The reason for that is that we want to combine both data, and we also want to compare them.



A huge difference is a fact that the Freelancer.com dataset is much bigger and detailed compared to the Motius dataset. The Freelancer.com dataset contains 30606 roles that are comparable to the positions in the Motius dataset. It has 32922 unique talents and 463536 bids by talents to the projects that represent the project-talent pairs.



Another significant contrast between the two datasets is the distribution of their positive and negative labels. Freelancer.com data carries approximately 14-15 applicants per projects, and only one of the applicants get selected as the person to implement the project. Differently,  Motius dataset includes multiple talents that advance to the next steps of the interviews. Therefore, we marked all of these talents that got invited with a positive label, and we marked the rest with negative tags. We will give detailed information about both datasets in the upcoming subsections.


\subsection{Freelancer.com Dataset}\label{implementation-subsection-freelancer}


\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth]{figures/FreelancerExample.png}
	\caption{An example project from the Freelancer.com Website}
	\label{fig:freelancer-example-project}
\end{figure}


As it can be seen in figure \ref{fig:freelancer-example-project}, a typical Freelancer.com project posting consists of a title, the description, and the relevant skills. For simplicity, the thesis at hand only concentrates on the skills and does not take the project description into account. Including other information would be the topic of another paper/thesis, as it would require natural language processing and other techniques ~\parencite{bird2009natural}.


\begin{figure}[htp]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/FreelancerTalentExample.png}
	\caption{The winner and other bidders to the same project}
	\label{fig:freelancer-example-talent}
\end{figure}


The figure \ref{fig:freelancer-example-talent} shows the bidders of the same project as above. The first one of the bidders has won the bidding race, which is decided by the creator of the project. The bidders include information such as a motivation text, the demanded monetary amount, their star rating until the time of bidding, amount of reviews they received, and their total earnings until that date. In this thesis, we only consider the money they demand, their star rating, and the number of reviews. For the sake of simplicity, we do not use the motivation text.



Each bidder lists their skills on their profile page, and the employers may check their profiles before hiring talents. The figure depicts the top skills of an arbitrary talent, which are listed in descending order. The number near each skill shows how many related projects the talent completed. That is why the amounts can range from one to more than hundreds. 



\begin{figure}[htp]
	\centering
	\includegraphics[width=0.5\textwidth]{figures/FreelancerTalentSkills.png}
	\caption{The list of tops skills by a talent on Freelancer.com web page}
	\label{fig:freelancer-talent-talent}
\end{figure}


The dataset encloses  941 unique skills, which are both technical and non-technical. However, the author of the thesis chose to limit these skills to 780, since some of them were not used in notable amounts, and the data can be expressed without using those skills. This dataset was scraped from Freelancer.com.


\subsection{Motius Dataset}\label{subsection:company-dataset}

The company dataset at hand is acquired from Motius GmbH. This dataset exported from their internal database and contains information about 795 talents and 375 roles. Each role includes the required skills for them, and each person has their skills listed. One difference to the Freelancer.com dataset would be that the talents also include skills that are associated with their original skill set. In theory, this is called association rules, and the skills that are mostly used together are considered to have a correlation score of 1. Because of these correlations, each talent has many skills listed, some of them highly correlated, and others are not correlated at all.


The amount of unique skills in the Motius data equals to 1768. Nonetheless, more than 85\% of the skills are used rarely, so the author reduced the unique set of skills to  202. Both of the datasets combined, 923 unique skills were given at least five times. A problem we have with the datasets is the naming. Since both Freelancer.com and Motius have used different names for skills, there are exists only a set of 59 common skills. Therefore, training both datasets together does not improve model like it is expected.



When all of Freelancer.com and Motius dataset are put together in their raw form, the matrix that contains all talent and project data reaches the size of 8 GB. Such a significant memory usage may create a big problem for the developers. When an operation like normalization is being done, the library \textit{Pandas} applies many copying operations, which doubles the memory usage and may crash, if the physical memory is below 32 GB. That is why the author employed embeddings as a dimensionality reduction mechanism [See \ref{subsection:using-embeddings}].




\section{Unsupervised Individual Recommender}\label{implementation-unsupervised-individual}

This section demonstrates how unsupervised individual recommenders got implemented.

\subsection{Recommendation by Similarity}\label{implementation-unsupervised-similarity}

As it was mentioned before, the unsupervised learning techniques focus on learning without the use of labels. Therefore, in the context of this thesis, we find similarities between projects and talents by using their feature vectors. The similarity measure we use for this part of the thesis is the cosine similarity ~\parencite{amatriain2011data}, which reads



\begin{equation}
\cos (x, y)=\frac{(x \bullet y)}{\|x\|\|y\|}
\end{equation}


In this formula for the cosine similarity, the big black dot denotes the inner product, and the double pipes are the Euclidian standard vector norm. The inputs  \textit{x and y} in the equation can correspond to a project-talent or a talent-talent pair. The types of input data are document vectors of n-dimensional space, and the formula calculates the similarity as the cosine of the angle between two vectors. The equation first calculates the dot product of the vectors and then divides it by the multiplication of the normal vectors.


To get the most important talents for the project, we calculate the cosine similarity between a selected project and every other talent. Then the algorithm sorts the talents by similarity and returns \textit{top n} bidders.



\subsection{Recommendation by Popularity}


Another unsupervised recommendation mechanism that is used as a baseline is the popularity recommender. The popularity recommender is an algorithm that is easy to implement, but it is also not easy to come up with new algorithms that perform better than the popularity recommender \cite{amatriain2015recommender}. The logic comes from the fact that the \textit{items} that are in demand approved by many \textit{talents}. That is why it is likely that selecting these items will increase user satisfaction ~\parencite{amatriain2015recommender}. 


For this specific project, the popular items that are in demand are the talents that finished the maximum amount of projects at Freelancer.com or Motius. Although the results will not be personal, recommending the same successful talents is a helpful strategy to acquire proven talents. The proof of this approach is shown in subsection \ref{subsubsection:eval-popularity}.


\subsection{Hybrid Recommendation}\label{section:hybrid}

As a last submethod of unsupervised individual recommenders, we can name the hybrid recommender. Hybrid methods are also called as \textit{ensemble learning} methods. This technique combines the results from multiple processes and outputs a new result ~\parencite{beliakov2015aggregation}. For our use case, the author implemented different versions that combine the similarity recommender and the popularity recommender. We can merge both of the recommenders by adding or multiplying the results. It is also possible to give different weights to these sources.


\section{Supervised Individual Recommender}\label{section:supervised}

Supervised learning means creating a model that learns with the help of labels. In our project, the author conceptualized labels as 0 or 1. 1 is for the case of the person got accepted for the project at Freelancer.com or Motius. 0 is for the case that the person got rejected. The models try to predict if the talent should be hired for the project or not(1 or 0).


For this task, we use two different versions; one version that takes all the skills as-is, the other one creates embeddings[See section \ref{research:embeddings}]. Both of the methods employ neural networks[See section \ref{research:nn}].


\subsection{Using Sparse Input}

\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth]{figures/FreelancerTalentSkillsMatrix.png}
	\caption{The talent skill matrix from freelancer.com}
	\label{fig:freelancer-talent-matrix}
\end{figure}

The first option that comes to mind is using the data as it is and training the model with them. The format of the talent data is shown in figure \ref{fig:freelancer-talent-matrix} and the projects skills matrix also have the same form with project names as keys.


It is crucial to normalize input data before training neural networks ~\parencite{sola1997importance}. It has two significant benefits; it reduces the estimation errors, and it cuts down the training time. That's why we normalize all of the inputs using \textit{StandardScaler} module of \textit{scikit-learn}. It uses equation  \eqref{eq:normal} to scale the data. In the equation, \textit{u} is the mean, and \textit{s} is the standard deviation of the data points. The equation reads

\begin{equation}
z = (x - u) / s .
\label{eq:normal}
\end{equation}


As it was mentioned before [See section \ref{section:datasets}], the Freelancer.com dataset contains some extra information like experience level, star rating, number of reviews, and hourly rate. These extra information of 10 example talents are shown in the figure \ref{fig:freelancer-talent-meta}. Since this information does not exist in Motius dataset, this subsection focuses only on the implementation with Freelancer.com dataset. The extra information that is mentioned is also scaled and input into the neural network. 


After normalizing data, we prepare the matrix that is fed into the neural network row by row. For each bid in the Freelancer.com data, we create a vector of length 1565. Seven hundred eighty of these values correspond to talent skills, the next 780 correspond to project skills, 4 of them are the extra information that is mentioned above and the last of them is for the outcome. The outcome is 1 for the case that the person received the project and 0 for the example that the person did not receive the project.



\begin{figure}[htp]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/FreelancerTalentMeta.png}
	\caption{The talent extra information matrix from Freelancer.com}
	\label{fig:freelancer-talent-meta}
\end{figure}

As one would expect, the model tries to guess if the person should be employed or not. Out of the \textit{321225} data points in total, we use 60\% for training, 20\% for the test, and the rest for validation. We split the data into those sets randomly using \textit{train\_test\_split} function of \textit{scikit-learn}. An important parameter not to miss is \textit{stratify}; since our dataset has  6\% positive and 94\% negative samples, we need to make sure that this ratio also remains in the sets. Not using this feature could result in the model always predicting the same negative results. Doing that means that the model would learn the same result, in every case ~\parencite{singh2015survey}.

After splitting the data, we can start with training. There also exists some important features that we need to use; these optional features all have different objectives, but they all serve to improve the results. These features are all supported by the packages \textit{Keras} and \textit{TensorFlow}, which are open-source neural network libraries. Keras is an abstraction layer for TensorFlow that lets the users train neural networks with a minimal number of lines ~\parencite{chollet2018deep}. While fitting the model with training data, Keras gives the option to add callbacks. The callbacks that we adopt are \textit{EarlyStopping}, \textit{ModelCheckpoint},  \textit{ReduceLROnPlateau} and \textit{TensorBoard} . As the name suggests, early stopping serves to prevent overfitting. In our case, it compares the validation loss of current batch with the previous one. If the validation loss does not drop for ten times, the training stops. The next callback model checkpoint is used complementary to early stopping. Model checkpoint saves the model weights of the batch with the minimum validation loss. After the training is complete, we load those model weights that achieved the best accuracy. ReduceLROnPlateau reduces learning rate when the validation loss has stopped improving. Lastly, TensorBoard is a visualization tool for TensorFlow. It produces model visions and graphs that show the evolution of the accuracy, loss, and learning rate. 

When we are training the model, we should also set the training weights for both labels manually. The dataset encompasses 6\% positive and 94\% negative samples, so we need to penalize the errors according to this rate. After training, the class weights are ignored and not used in testing/predicting.


The figure \ref{fig:tensor-board-sparse}  depicts the model that is used to predict if a talent should be employed or not. The direction of the graph starts at the bottom of the image and goes up. Like it was mentioned before, the model expects three feature vectors. These vectors are defined as the skill vectors of the project, the skill vector of the talent and extra information of the talent(e.g., hourly rate, total experience). 

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/TensorBoardSparseCropped.png}
	\caption{The graph that explains the sparse input model}
	\label{fig:tensor-board-sparse}
\end{figure}

For each of the inputs, a dense layer exists with the number of neurons equal to the number of features. Making this decision means that project and talent layers contain 780 neurons, and profile information layer contains four neurons. For these layers, we use \textit{relu} activation, \textit{l1} regularization with the value \textit{0.0001} and we initialize the weights with \textit{he normal} \cite{hanin2018start}.


After the activation functions, all layers get concatenated horizontally. Concatenation layer is followed by a dropout layer with half of the neurons are disabled randomly. Next one in the model is a dense layer with 256 nodes, which possesses the same activation function, regularization, and weight initialization methods as the previous dense layers. The model accommodates the last dropout layer and ends with the main output. The output is only a one node layer and involves a \textit{sigmoid} activation function that squeezes the output value to be between 0 and 1. The weight initializer of the last layer is \textit{glorot uniform} \cite{pedamonti2018comparison}.

Each neural network has the aim of minimizing its cost function ~\parencite{Goodfellow-et-al-2016}. The cost function that we chose is \textit{mean squared error}[See ~\eqref{eq:mean-squared-error}]. In the equation. $C$ is the cost function, $n$ is the total number of data points, $y(x)$ are the predicted results, and $a$ is the correct result. This example of the cost function is used mostly for regression tasks and calculates the mean squared difference of the actual value and the predicted output value. The metric we use is accuracy, and more information about it can be found in ~\autoref{chapter:evaluation}. Mean squared error is defined as

\begin{equation}
C \equiv \frac{1}{2 n} \sum_{x}\|y(x)-a\|^{2} .
\label{eq:mean-squared-error}
\end{equation}


\subsection{Using Embeddings}\label{subsection:using-embeddings}

High-dimensional spaces and distributions prove to be unexpected and completely differ from low-dimensional spaces. The empty space phenomenon and other ones are examples of the \textit{curse of dimensionality}. With the help of embeddings layers, we can represent high-dimensional data in low-dimensions  ~\parencite{lee2007nonlinear}.


Although deep neural networks can avoid the curse of dimensionality ~\parencite{poggio2017and}, we still need to use embeddings layers for spatial reasons. In the previous sections, we mentioned that there are 780 unique skills for Freelancer.com data and 923 skills if we also add Motius data. Having all of this data means that the data has 923 dimensions and we know that the information is sparse, most of the data matrices consist of zeros so that we can reduce the dimensionality [See section \ref{research:embeddings}].

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/EmbeddingThesis.png}
	\caption{3D version of the embedding space that is created for projects of this thesis}
	\label{fig:embedding-projection}
\end{figure}


\subsubsection{Preprocessing}

For both Freelancer.com and Motius data, we know the skill levels of projects and talents for various skills. Instead of having some positive and hundreds of zero skill values for each project/talent, we can set a skill threshold. This threshold implies skills above or equal to the limit are positive, and the remaining entries are set to zero. In this way, each talent/skill holds a list of skills they know/require. However, another constraint that needs to be addressed is the maximum length of the padded skill matrix because neural networks require a fixed input shape. Therefore, the talent/project maximum amount of positive skills is determined. For Freelancer.com data, this is 18, which means all skills vectors are padded with zeroes to have the length of 18. 

In the case of Motius data, the topic is more complicated. The ~\autoref{subsection:company-dataset} explained how the correlation mechanism of the company data works. To describe it briefly, Motius stores user skills and other skills that are correlated for each user. Including this data affects that there exist many skills for each user, but most of these skill levels are low. Here the highest skill level is 2, and the smallest is 0.



\begin{figure}[htp]
	\centering
	
	\pgfplotstableset{col sep=&, row sep=\\}
	% This should probably go into a file in data/
	\pgfplotstableread{
		a & b    \\
		0.1 & 780 \\
		0.2 & 732 \\
		0.3 & 676 \\
		0.4 & 605 \\
		0.5 & 530 \\
		0.6 & 463 \\
		0.7 & 386 \\
		0.75 & 361 \\
		0.8 & 325 \\
		0.9 & 299 \\
		1.0 & 269 \\
	}\exampleA
	\pgfplotstableread{
		a & b    \\
		0.1 & 132 \\
		0.2 & 112 \\
		0.3 & 94 \\
		0.4 & 71 \\
		0.5 & 57 \\
		0.6 & 44 \\
		0.7 & 28 \\
		0.75 & 21 \\
		0.8 & 16 \\
		0.9 & 12 \\
		1.0 & 9 \\
	}\exampleB
	% This should probably go into a file in figures/
	\begin{tikzpicture}
	\begin{axis}[
	ymin=0,
	legend style={legend pos=outer north east},
	grid,
	thick,
	ylabel=Threshold,
	xlabel=Amount of x
	]
	\addplot table[x=a, y=b]{\exampleA};
	\addlegendentry{Amount of Motius talents};
	\addplot table[x=a, y=b]{\exampleB};
	\addlegendentry{Maximum skill vector length};
	\end{axis}
	\end{tikzpicture}
	\caption[Threshold figure]{Effect of threshold selection on talents and maximum skill vector length}\label{fig:threshold-selection}
\end{figure}

The effect of different threshold values on Motius data is shown on \autoref{fig:threshold-selection}. Without any threshold, there is a couple of Motius projects with the maximum skill length of 21. Projects do not specify skill levels, so these are taken as they are. That is why we also wanted to have a similar maximum length for Motius talents. When there is no threshold, there are 780 Motius talents with at least one skill value, but the maximum skill vector length is 132. We would not want to implement this version because the maximum range of 132 will create millions of zeroes in the dataset, which we tried to avoid in the first place. Setting the threshold to a high value(like 1 or more) is also not optimal since it limits the maximum skill vector length to 9 and number of Motius talents to 269. Having such a high value would decrease the amount of information we have would significantly decrease because the Freelancer.com data also has a maximum length of 18. Therefore, the optimum threshold value we reached is \textit{0.75}. As a consequence, the number of Motius talents to 361 and limits the maximum skill vector length to 21, just like the project with the most skills.

\autoref{fig:embedding-training-matrix} depicts the training data with full skill matrix. The columns with the numbers in range 0 to 20 are the indices of the talent skills and the columns with the names 21 to 41 are project skills indices.  The version of the image is the one with the Motius and Freelancer.com data combined. In the variant with only Freelancer.com data, we have skill vector lengths of 18 and the extra information of talents included.

\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth]{figures/EmbeddingTrainingMatrix.png}
	\caption{Training data that contains padded embedding skill vectors}
	\label{fig:embedding-training-matrix}
\end{figure}



\subsubsection{Simpler Architecture for Company Dataset}

The Freelancer.com dataset has a massive advantage over Motius data, which is the extra information that we know about the applicants. When we use both datasets together to train a model, we can limit the inputs to talent and project skills. 

\autoref{fig:model-code} illustrates the simplified version of the \textit{Python} code that constructs the model to predict the hiring result. The \textit{features} parameter of the model building function corresponds to the length of the padded skill vector, and the next parameter, \textit{dimensions}, represents the total amount of unique skills. Embedding layers in Keras expect the arguments \textit{input dimension}, \textit{output dimension}, \textit{input length} and the optional flag \textit{mask zero}. As embeddings only accept positive integers, input dimension should be the size of the vocabulary, which is the number of total skills in the recommender system. The value of the output dimension can be decided by the developer and explains the size of the desired output dimension. Although no scientific document states an ideal output dimension, the trial-and-error method showed that the best result is achieved with the fourth root of the number of dimensions. The additions of one in multiple places in the code are due to using the mask zero operation. Zeros in rows get filtered out, which increases the performance and speeds up the training process. The cost function that we use is \textit{binary crossentropy} because we want to optimize the process of hiring or not hiring talent to the project \cite{murphy2012machine}. Lastly, \textit{sigmoid} activation function squeezes the output value to be between 0 and 1 \cite{pedamonti2018comparison}.


\section{Unsupervised Group Recommender}\label{section:unsupervised-group-rec}

In this section, we explain the process of recommending multiple talents to supergroups. The methods that are used for this part are derivations of the ones that are used in individual recommenders. Therefore, the basic concepts that are employed before also apply here. 

In order to perform group recommendations, project-role, or project-project information are needed. The website Freelancer.com shows other projects from the same supervisor, which can be combined. Then these projects will form a super project, and projects can be treated as roles of a more significant project. For Motius data, we already possess this information as project-role data. Roles of Motius correspond to the projects in the Freelancer.com data. In terms of simplicity and shortness, we only take Freelancer.com dataset with groups of size five into account. 

\subsection{Baseline Recommender}

The basic approach to unsupervised group recommendations would be calculating the cosine similarity between each project and talents. Then pick the best talents and listing them. However, the results will not be diverse, and we can pick talents that have similar skills to each other. We want to avoid that [See section \ref{ev-unsupervised-group-diversity}] and have diverse recommendations for each project.


\subsection{Diverse Recommender}\label{implementation-diverse}

Because of the reasons above, we want to create the recommendation list diversely from the beginning. The topic of diversity is already explained before [See section \ref{section:novelty_and_diversity}] and the pseudocode to enhance diversity is shown below.

\begin{algorithm}
	\begin{algorithmic}
		\STATE $R\gets \emptyset$
		\WHILE {$|R| \le k$}
		\STATE $i*\gets \arg \max _ { i \in C - R } g ( R \cup \{ i \} , \lambda )$
		\STATE $R\gets  R \cup \{ i * \} $
		\ENDWHILE
		\RETURN $R$
		\label{eq:diversity-enhancement}
	\end{algorithmic}
	\caption{Diversity Enhancement Algorithm}
\end{algorithm}


In the algorithm above, we first create an empty recommendation list \textit{R} and set a recommendation length \textit{k}. In our example, we only consider the groups with project amount of 5, so \textit{k} is five as well. After that, we find the optimal candidate that has not been selected yet, is relevant to the project at hand and is also diverse to the other selected candidates. Finding the optimal candidate can be tuned with the help of \eqref{eq:diversity-equation}. The $\lambda$ parameter in the equation can be optimized to value the relevancy or diversity more; $\lambda$ of 1 means to only consider variety, 0 factors to consider relevancy and 0.5 gives the balanced result. $f _ { r e l }$ in the equation stands for the relevancy score of the item, and $d i v ( R )$ tells the diversity between the items in the list. When we receive the optimal candidate from the equation, we add the talent to the recommendation list and iterate until we have enough talents for the whole group. The equation for the diversity is

\begin{equation}
g ( R , \lambda ) = ( 1 - \lambda ) \frac { 1 } { | R | } \sum _ { i \in R } f _ { r e l } ( i ) + \lambda d i v ( R ) .
\label{eq:diversity-equation}
\end{equation}

When we compare the diversity of the baseline approach to the diverse group recommendation, it is obvious that the diversity of talents recommended has increased. The evaluation algorithm for diversity and other relevant measures can be found in \autoref{chapter:evaluation} [See section \ref{ev:unsupervised-group-rec}].

\section{Supervised Group Recommender}\label{section:supervised-group-rec}

The previous section was about performing group recommendations with unsupervised learning. This section will do the same job using a supervised learning model that we used in \autoref{section:supervised}.


\autoref{eq:diversity-equation} includes a $f _ { rel } $, which is a relevancy score and a diversity rate that can be computed via cosine similarity, neural networks, or other methods. In contrast to the unsupervised method, we calculate the relevancy score using the neural network that we used in \autoref{section:supervised}.

What we do in the individual supervised learning part is, training all parameters jointly, which is called end-to-end learning. This idea was also the first aim for supervised group recommender approach. However, the data for such knowledge does not exist. To apply it, we would need data on hiring decisions for the groups, not just projects. Since we do not have such information, we would have to generate it with a separate algorithm. In the end, it would not bring much, because the model would learn the data generation algorithm and would not have an effect on the real-life hiring prediction.


Due to the reason above, step by step learning process is applied. The first step of the process is training the model to optimize the individual hiring of talents. Then, we predict the relevancy score for each project-talent pair. For diversity score, we use the cosine similarity between the talents. After set those functions, the algorithm \ref{eq:diversity-enhancement} is applied. The supervised learning only optimizes the relevancy score, and the diversity still gets calculated via the unsupervised approach.


In the end, this method increases diversity according to the evaluation methods that are listed in \autoref{chapter:evaluation}.

\section{Group Recommendation using Clustering}

Clustering is the process of dividing data into different groups. To perform different multi-project recommendations, we can pick talents from clusters. Therefore, we can be sure that they are dissimilar. 

Since k-means clustering can suffer from the curse of dimensionality~\parencite{steinbach2004challenges}, To prevent it, it is logical to reduce the dimensionality first. The choice of the author to reduce dimensionality is \textit{Principal Component Analysis}.

The central idea of principal component analysis (PCA) is to reduce the
dimensionality of a data set consisting of a large number of interrelated
variables while retaining as much as possible of the variation present in
the data set. This idea is achieved by transforming to a new set of variables,
the principal components (PCs), which are uncorrelated, and which are
ordered so that the first few retain most of the variation present in all of
the original variables~\parencite{jolliffe2011principal}. 


To determine the number of PCs, we can check the explained variance ratio for the different amount of PCs. Here, it makes sense to note that a higher number will affect the clustering model negatively, and a lower number will not be able to capture everything in the dataset. The author of the thesis experimented with different values.

K-means clustering requires a \textit{k} value that determines the number of clusters the model is going to create. The ideal number of clusters can be verified by calculating the silhouette scores for a different number of clusters. The figure \ref{fig:pca-silhouette} shows silhouette scores for different cluster amounts. Silhouette score calculates the similarity of a data point to its cluster compared to other clusters \parencite{rousseeuw1987silhouettes}. For this task, we use the equations \eqref{eq:silhouette-a}, \eqref{eq:silhouette-b}, \eqref{eq:silhouette-c}. In the equations, different distance metrics can be employed. The choice of the author is the Euclidian distance.  The equation \eqref{eq:silhouette-a} calculates the mean intra-cluster distance for each sample and the next \eqref{eq:silhouette-b} computes mean nearest-cluster distance for each sample, which means the distance between a sample and the nearest cluster that the sample is not a part of. $d(i, j)$ in the \eqref{eq:silhouette-a} stands for the chosen distance function and the $C_{i}$ refers to the number of clusters. The last function \eqref{eq:silhouette-c} converts the results of the first two equations into silhouette coefficients. The mean of all silhouette coefficients from every sample gives the silhouette score for that \textit{k} value. Higher silhouette scores suggest that the samples well matched to its cluster and poorly matched to neighboring clusters. In the example of \ref{fig:pca-silhouette}, it makes sense to select a value like 30. To visualize results, we project the centers of the clusters on a 2D space[See \ref{fig:kmeans-centers}]. The X-axis of the graph is the maximum value in each cluster center coordinate, and the Y-axis of the graph is the maximum value in each cluster center coordinate. The relevant equations are defined to be

\begin{equation}
a(i)=\frac{1}{\left|C_{i}\right|-1} \sum_{j \in C_{i}, i \neq j} d(i, j) , 
\label{eq:silhouette-a}
\end{equation}

\begin{equation}
b(i)=\min _{i \neq j} \frac{1}{\left|C_{j}\right|} \sum_{j \in C_{j}} d(i, j) ,
\label{eq:silhouette-b}
\end{equation}

\begin{equation}
s(i)=\frac{b(i)-a(i)}{\max \{a(i), b(i)\}} .
\label{eq:silhouette-c}
\end{equation}

\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth]{figures/PCASilhouette.png}
	\caption{Silhouette scores of many different \textit{k} values of k-means}
	\label{fig:pca-silhouette}
\end{figure}


Next, we benefit from another function of the PCA; \textit{inverse\_transform}. Inverse transform takes the cluster centers as an input and converts them to full talent values. This conversion promises that we treat each cluster center like talent and transform their values to skill values and extra information. In end, we possess an average skill vector for every cluster [See figure \ref{fig:cluster-centers-matrix}]. The figure contains some part of the skill vectors of the first three average talents. For example the cluster(segment) 0 in the figure has exceptional \textit{Adobe Illustrator} skills. Segment 1, on the other hand, is an all-rounder. Lastly, segment 3 is a \textit{c\#} developer.  It must be noted that these values are calculated after standard scaling \cite{grus2019data}.

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/KMeansCenters.png}
	\caption{Centers of clusters that are projected on a 2D space}
	\label{fig:kmeans-centers}
\end{figure}


After we execute clustering, we can start with the group recommendation process. The recommendation can be operated both supervised[See \ref{section:supervised-group-rec}] or unsupervised[See figure \ref{section:unsupervised-group-rec}]. The same principles apply, and we calculate the relevancy score with cosine similarity or neural networks. In contrast to the other methods, the algorithm computes the relevancy score of the project and average cluster skills [See figure \ref{fig:cluster-centers-matrix}]. This way, we determine the ideal cluster for the project. When a project got recommended talent from a specific cluster, that cluster is excluded from the next projects in the group. Therefore, diversity in a group is guaranteed. After the selection of the optimal cluster, the best candidate in that cluster is chosen via neural networks or cosine similarity.

\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth]{figures/ClusterCentersMatrix.png}
	\caption{Examples of some centers of clusters that are projected on a 2D space}
	\label{fig:cluster-centers-matrix}
\end{figure}



\section{Dashboard to show data and enter feedback}

\subsection{General Dashboard}

Another big part of the thesis is the dashboard that was built for various purposes; these purposes are showing individual unsupervised, supervised and hybrid recommendations for Motius and Freelancer.com datasets, showing group recommendations using unsupervised, supervised and hybrid methods and allowing to enter feedback, that has direct and indirect effects on the results.

The dashboard adopts the front-end that is programmed with \textit{Vue.js} and a back-end that employs \textit{Flask}. Vue.js is a front-end development framework that can be programmed with JavaScript. Flask is a back-end development framework that can be called with Python. The reason to use Vue.js is because of personal reasons; it is a reactive, modern framework that is easy to develop \cite{you2018vue}. On the other hand, Flask is chosen because it is a popular lightweight Python framework \cite{grinberg2018flask}. Since the rest of the machine learning training/prediction was done on Python, the author seized the opportunity to reuse/adapt the same codebase. 

Docker is a container virtualization technology, which is like a very lightweight virtual machine. Adding Docker to our software stack gives the advantage of portability. This is important for various reasons; first of all, the operating system choice of the author is \textit{MacOS}, but most of the servers run different flavors of \textit{Linux}. All of the different operating systems have different installation methods, different pre-installed libraries, and different dependencies. Docker solves this problem by standardizing the building and running operations of virtual machines \cite{anderson2015docker}.


\begin{figure}[htp]
	\centering
	\includegraphics[width=0.5\textwidth]{figures/DashboardMain.png}
	\caption{Main screen of the dashboard}
	\label{fig:dashboard-main}
\end{figure}


The main screen of the dashboard is shown in figure \ref{fig:dashboard-main}, and it contains a search box and a dropdown. When users type anything on the search box, the front-end sends a \textit{get request} \cite{masse2011rest}. As the back-end receives the request, it checks the database for the text that is given by the user. Then, the back-end returns related projects as a list. 


The dropdown on that screen has three options; \textit{All},  \textit{Motius} and  \textit{Group}. The \textit{all} mode searches the input text in all projects database that includes Freelancer.com and Motius projects. As the name suggests, Motius mode only returns the company projects, and the group mode returns group numbers, which are a combination of various projects[See figure \ref{fig:dashboard-projects}]. 

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.75\textwidth]{figures/DashboardProjects.png}
	\caption{A snippet from the list of all projects that start with the letter \textit{a}}
	\label{fig:dashboard-projects}
\end{figure}

\subsection{Individual Recommendations}

When users click on any of the projects that are listed in figure \ref{fig:dashboard-projects}, they receive recommendations with respective scores. For the case of individual recommenders, these scores can be from the neural network model, cosine similarity, or hybrid.

The back-end of these different recommenders is all explained in the previous subsections. The figure \ref{fig:dashboard-individual} shows individual recommendations for an artificial intelligence project. There is a dropdown that has choices such as \textit{neural networks}. \textit{cosine similarity} and \textit{hybrid}. Baseline neural networks give individual recommendations that come from the machine learning model. Cosine similarity method checks the angle between talent and project vectors. Lastly, hybrid mode combines neural networks and unsupervised similarity to come up with new predictions.

\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth]{figures/DashboardIndividual.png}
	\caption{A screenshot from the list of all recommendations from neural networks for the project \textit{a.i. \& software engineer}}
	\label{fig:dashboard-individual}
\end{figure}

\autoref{fig:dashboard-individual} shows the results for the project \textit{a.i. \& software engineer} on the dashboard that is built by the author. Names of the talents that were recommended are anonymized, but the rest of the data are untouched. The example project at hand requires the skills \textit{computer vision}, \textit{deep learning}, \textit{machinelearning}, \textit{opencv} and \textit{python}. Although the skills of the person one is not shown(because that person retains 21 skills, which are too long for the figure), person 1 is not the talent with the most overlapping skills. Instead, person 1 is a talent that was recommended the most by the Motius internal recommender. Next, person 2 knows no skills that the project requires. This lack of knowledge aligns with the fact that it is hard to debug neural networks, and they are mostly referred to as \textit{black-boxes} [See chapter \ref{chapter:evaluation}] \cite{benitez1997artificial}.

\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth]{figures/DashboardIndividualHybrid.png}
	\caption{A screenshot from the list of all recommendations from neural networks for the project \textit{a.i. \& software engineer}}
	\label{fig:dashboard-individual-hybrid}
\end{figure}

In contrast to the figure \ref{fig:dashboard-individual}, figure \ref{fig:dashboard-individual-hybrid} demonstrates the adequate talents for the same project as before. However, talents that are listed are different. As it was explained in \ref{section:hybrid}, hybrid practice multiplies the results of from the neural networks and skill vector similarity. This way, the results that are recorded, always have some common skills. In the example, these skills are \textit{computer vision} and \textit{machine learning}.

\subsection{Group Recommendations}

The dashboard can also perform group recommendations. For the case of group recommenders, the scores can be from baseline neural networks, baseline cosine similarity, diverse neural networks, or diverse cosine similarity [See chapter \ref{chapter:evaluation}].

Baseline cosine similarity, reveal the list of best talents for each project using skill vector similarity and baseline neural networks do the same with neural networks. Diverse cosine similarity and diverse neural networks show a list of talents for each project of a group, and these talents are sorted by their relevancy to projects and the diversity between other talents in the group.

\autoref{fig:dashboard-group} shows the recommendation results for a real-life group with anonymized names. On the top-right part of the figure, a dropdown can be seen. This dropdown reads \textit{Diverse Similarity}. Other options in the dropdown are \textit{neural networks}, \textit{similarity} and \textit{diverse neural networks}. Meaning of these options is already explained in this section. This selection option makes sure that the chosen talents for each project have similar skills and are diverse to each other simultaneously. Between the group name and recommendation mode, a slider is located. This slider determines the constant for the diversity enhancement formula [See \eqref{eq:diversity-equation}]. This diversity constant can be tuned to value the relevancy or diversity more; a value of 1 means to only consider diversity, 0 means to only consider relevancy, and 0.5 gives the balanced result. There are also options to check project and talent skills. Last but not least, the dashboard provides the option to rate all talents positively or negatively. This part of the thesis is explained in the next section [See section \ref{section:feedback-learning}].

\begin{figure}[htp]
	\centering
	\includegraphics[width=\textwidth]{figures/DashboardGroup.png}
	\caption{A screenshot from the list of all recommendations from diverse cosine similarity for the group 9}
	\label{fig:dashboard-group}
\end{figure}




\section{Improvement of Recommendations via Feedback Learning}\label{section:feedback-learning}

The arrows in the figures \ref{fig:dashboard-group}, \ref{fig:dashboard-individual-hybrid} and \ref{fig:dashboard-individual} correspond to the feedback learning. Recruiters or Human Resources employees that use the dashboard may send positive or negative feedback to every recommendation. 

The feedback that is provided by real talents may have direct or indirect effects. To understand the process, it may make sense to check the figure \ref{fig:tensorboard-feedback} first. Feedback data is given to the model as a separate input, and this input is followed by a layer with one node with \textit{tanh} activation function. Tanh activation is chosen because the bias can be negative or positive \cite{pedamonti2018comparison}. The output of the bias activation functions is \textit{added} to the result that comes from project-talent information. In this context, adding means actually the mathematical addition operation [See \ref{fig:feedback-model-code}]. Due to this addition, the outcome of personal feedback has a direct effect, even without retraining. 

The default value for any talent bias is 0, and they may be increased up to 1 with positive feedbacks and decrease to -1 with negative feedbacks. These values are added to the result that comes from the dense layer, which gets data from talent and project skills. Since personal feedback is stored in the database immediately, they can directly be used and have a direct effect on the total results.


Feedback learning also has an indirect effect;  entering feedback changes the labels of previous training data. This change signifies that positive feedback changes the label of a result to 1(positive) and negative feedback changes it to a 0(negative). That is why, when the developer retrains the model with the new data, it also modifies how the model learns and may also have an impact on other projects.


\begin{figure}[htp]
	\centering
	\includegraphics[width=0.8\textwidth]{figures/TensorBoardFeedback.png}
	\caption{Neural networks model with the addition of feedback loop bias}
	\label{fig:tensorboard-feedback}
\end{figure}



\section{Summary}

This chapter analyzed the practical realization of this thesis exhaustively. We explained how we programmed different recommenders with diverse approaches. We also revealed the dashboard that puts everything together and the proposal to improve recommendations with the help of feedback learning. 

The next chapter focuses on the evaluation of the results that were programmed in the scope of this section.

