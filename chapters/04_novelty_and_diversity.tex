% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\section{Diversity}\label{section:novelty_and_diversity}

In the first decades of recommender systems, the main concern was running predictions with a high accuracy rate. Since the beginning of 2000s other properties like utility, novelty, diversity are also percieved as important metrics in addition to the accuracy \cite{Hurley:2011:NDT:1944339.1944341}. In this section, we explain the motivation and techniques that are about diversity. 

\subsubsection{Why Diversity in Recommendation}

Adding diversity as a target property of the desired outcome brings the recommendation problem to a wider perspective instead of only focusing on accuracy \cite{McNee:2006:AEA:1125451.1125659}. The are also other properties that should be considered according to the needs, which are described in the previous section. 

Recommender systems get the information of user clicks, reviews, purchases that are driven by the user interest and try to have perfect guess for the users. However, user interests are complex, dynamic, context-dependent, heterogeneous and contradictory. That's why prediction of user needs just by looking at accuracy is a difficult task and may lead to decreased user satisfaction. Diversity can be a good strategy to optimize the chances that at least some item pleases the user, by widening the range of different item types and characteristics, rather than suggesting in a too narrow and risky range \cite{castells2015novelty}.

On the other hand, from the user perspective, diversity is generalle desirable, as it increases the user satisfaction. According to the consumer behaviorists, humans seek variety, they get satisfied from novelty, unexpectedness, change and also humans have a genuine desire for the unfamiliar \cite{castells2015novelty}. Not employing diversity may also lead to too much persinalization which causes a filter buble, meaning that there is a healty level of diversity required \cite{Nguyen:2014:EFB:2566486.2568012}. The increase of user satisfaction also leads to increased activity, revenues and customer loyalty.

In context of this thesis, the main task is recommending talents to roles of the projects. If the system suggests people with very similary or overlapping skills, it wouldn't be too beneficial for the recruiters, since they would like to have a team that can tackle a wide range of topics.

\subsection{Diversity Evaluation}

In this subsection, we show different options to evaluate the diversity of recommender systems. We first present the notation and go on with the methods.

Similar to the notation that we used before, $i$ and $j$ denote items, $u$ and $v$ are used for users, and $I$ and $U$ symbolize the set of all items and users. $I_u$ and $U_i$ are shorthand symbols for items that the user $u$ has interacted with and users that has interacted with the item $i$ respectively. $r ( u , i )$ is the set of ratings for the ratings from user $u$ to the item $i$. The letter $R$ is used to indicate the recommendations to the target user $u$ \cite{castells2015novelty}.

\subsubsection{Average Intra-List Distance}

Perhaps the most frequently used diversity metric is the average intra-list distance \cite{castells2015novelty}: 

$$\mathrm { ILD } = \frac { 1 } { | R | ( | R | - 1 ) } \sum _ { i \in R } \sum _ { j \in R } d ( i , j )$$


As the name suggests, it's aim is to calculate the average diversity inside a list. A distance function is picked and the distance of each item in the list to other items in the same list are calculated. The results gives us the diversity. This method is also employed in the evaluation part of the implementation and cosine similiarity is picked for the distance function. The similarity of the list items can be easily calculated with the formula $Inter-List-Similarity = 1 - ILD$ [See chapter \ref{chapter:evaluation}].


\subsubsection{User-Specific Unexpectedness}

Unexpectedness is property that can lead to user satisfaction. The formula below is the way to calculate it for a user:

$$
Unexp = \frac { 1 } { | R | \left| \mathcal { J } _ { u } \right| } \sum _ { i \in R } \sum _ { j \in \mathcal { J } _ { u } } d ( i , j )
$$
where 
$$
\mathcal { J } _ { u } \stackrel { \mathrm { def } } { = } \{ i \in \mathcal { J } | r ( u , i ) \neq \emptyset \}
$$

In words, the distance between recommended items and the items that the user has already interacted with are averaged. This method is also used in the evaluation part of the thesis [See chapter \ref{chapter:evaluation}]. Another way to calculate the unexpectedness is with this formula: 

$$
 Unexp = | R - E X | / | R |
$$

In the above formula, $EX$ is the set of items that the user expects \cite{castells2015novelty}.

\subsubsection{Inter-Recommendation Diversity Metrics}

In the following paragraphs, we show methods to calculate the diversity of the whole system. These results can be used to compare diversity between recommendation methods. Although these methods are programatically used in the scope of this thesis, they are not presented because of space reasons.

\paragraph{Aggregate Diversity}

We can calculate the aggregate diversity for the all users in the system to compare the results with the other recommender systems. This way, we compare the diversity of different systems \cite{castells2015novelty}.

$$
Aggdiv = \left| \bigcup _ { u \in{ U } } R _ { u } \right|
$$

\paragraph{Gini Index}

$$
Gini = \frac { 1 } { |{ J } | - 1 } \sum _ { k = 1 } ^ { | J | } ( 2 k - | J |  - 1 ) p \left( i _ { k } | s \right)
$$

, where

$$
p ( i_{k} | s ) = \frac { | \{ u \in { U } | i \in R _ { u } \} | } { \sum _ { j \in J } | \{ u \in { U } | j \in R _ { u } \} | }
$$

To calculate the gini index, the interacted items are first sorted in an ascending order by the chosen probability, which is the second equation above. In that equation, $k$ is the number of the least recommended item. In the end, a gini index close to zero means items are chosen equally often and a value of one would mean a single item is always chosen \cite{castells2015novelty}.

\paragraph{Shannon Entropy}

$$
\mathrm { H } = - \sum _ { i \in \mathcal { J } } p ( i | s ) \log _ { 2 } p ( i | s )
$$

Shannon Entropy is a logically similar to the \textit{gini index} and they are calculated similarly. In the end, if the entropy is zero, a single item was always chosen and if the entropy is $log2(\#items)$, then each item is equally chosen \cite{castells2015novelty}.

[TODO if some place left, add IUD, ISD, embeddings and NN maybe]

\subsection{Diversity Enhancement Approaches}

There are also some methods to not just evaluate but also increase the diversity. The methods that we employed are reranking and clustering. These methods are explained in the chapter \ref{chapter:implementation}.

\subsection{Summary}


In scope of this chapter, we gave detailed information about the types of recommender systems with focus on the content-based recommendation. Then, we listed the evaluation properties that can lead to user satisfaction. Lastly, we disclosed the property that we chose, which is the diversity and illustrated how diversity can be calculated.
